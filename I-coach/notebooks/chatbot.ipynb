{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        " response = {\n",
        "            'pushups_beginner': \"For beginner push-ups: Start on your knees (modified push-up). Keep your body straight, hands shoulder-width apart. Lower chest to ground, push back up. Aim for 3 sets of 5-10 reps. Focus on form over quantity!\",\n",
        "\n",
        "            'pushups_progression': \"To progress push-ups: Master regular push-ups first (3x15). Then try: incline push-ups → regular → decline → diamond push-ups → one-arm push-ups. Increase reps gradually before moving to harder variations.\",\n",
        "\n",
        "            'pushups_mistakes': \"Common push-up mistakes: Sagging hips, flaring elbows too wide, incomplete range of motion, holding breath. Keep core tight, elbows at 45°, chest touches ground, breathe throughout movement.\",\n",
        "\n",
        "            'pullups_beginner': \"Beginner pull-ups: Start with dead hangs (30s), then negative pull-ups (jump up, lower slowly). Use resistance bands or assisted pull-up machine. Practice scapular pulls. Be patient - pull-ups take time to develop!\",\n",
        "\n",
        "            'pullups_assistance': \"Assisted pull-up options: Resistance bands around knees, assisted pull-up machine, partner holding feet, or box-assisted pull-ups. Gradually reduce assistance as you get stronger.\",\n",
        "\n",
        "            'pullups_grip': \"Pull-up grips: Wide grip (lats focus), shoulder-width (balanced), chin-ups (underhand, biceps focus). Start with shoulder-width overhand grip for best beginner results.\",\n",
        "\n",
        "            'hammer_curl_form': \"Hammer curl technique: Stand straight, dumbbells at sides with neutral grip (palms facing each other). Curl up keeping elbows stationary, squeeze at top, lower slowly. Don't swing or use momentum!\",\n",
        "\n",
        "            'hammer_curl_weight': \"Hammer curl weight selection: Start with 10-15 lbs for beginners. You should complete 8-12 reps with good form, struggling on last 2-3 reps. Increase weight when you can do 15 reps easily.\",\n",
        "\n",
        "            'bench_press_beginner': \"Beginner bench press: Lie flat, feet on floor, grip bar slightly wider than shoulders. Lower bar to chest with control, pause briefly, press up smoothly. Start with empty barbell (45 lbs) to learn form. Always use a spotter!\",\n",
        "\n",
        "            'bench_press_safety': \"Bench press safety: ALWAYS use a spotter or safety bars. Don't lift alone. Warm up properly. Use proper form over heavy weight. Know your limits. Have a clear escape plan if you fail a rep.\",\n",
        "\n",
        "            'bench_press_grip': \"Bench press grip: Hands slightly wider than shoulders, full grip (not thumbless), wrists straight. Grip too wide reduces range of motion, too narrow stresses wrists. Find your comfortable, strong position.\",\n",
        "\n",
        "            'squat_beginner': \"Beginner squat: Stand with feet shoulder-width apart, toes slightly out. Keep chest up, core tight. Sit back like sitting in chair, knees track over toes. Go down until thighs parallel to floor, drive through heels to stand.\",\n",
        "\n",
        "            'squat_depth': \"Squat depth: Aim for thighs parallel to floor (90°) minimum. Deeper is better if you have mobility. Stop where you can maintain good form. Improve flexibility gradually to increase depth safely.\",\n",
        "\n",
        "            'squat_knee_issues': \"Knee-friendly squats: Ensure knees track over toes, don't cave inward. Start with bodyweight, focus on proper form. Consider box squats or wall squats. If pain persists, consult a physical therapist.\",\n",
        "\n",
        "            'workout_frequency': \"Workout frequency: Beginners: 3x per week with rest days between. More advanced: 4-5x per week. Listen to your body. Quality over quantity - better to do 3 good workouts than 6 poor ones.\",\n",
        "\n",
        "            'rest_recovery': \"Rest and recovery: Allow 48-72 hours between training same muscle groups. Get 7-9 hours sleep. Stay hydrated. Light activity on rest days is fine. Your muscles grow during rest, not just during workouts!\",\n",
        "\n",
        "            'sets_reps': \"Sets and reps: Beginners: 2-3 sets of 8-12 reps for most exercises. Strength: 3-5 sets of 1-5 reps. Endurance: 2-3 sets of 15+ reps. Start conservative and progress gradually.\",\n",
        "\n",
        "            'warm_up': \"Warm-up routine: 5-10 minutes light cardio, then dynamic stretches and movement prep. For upper body: arm circles, shoulder rolls. For lower body: leg swings, bodyweight squats. Prepare your body for work ahead!\",\n",
        "\n",
        "            'motivation': \"Stay motivated: Set realistic goals, track progress, find a workout buddy, vary your routine, celebrate small wins. Remember why you started. Progress isn't always linear - stay consistent and trust the process!\",\n",
        "\n",
        "            'general_advice': \"General fitness advice: Start slowly and focus on form. Be consistent rather than perfect. Progressive overload is key. Listen to your body. Combine exercise with proper nutrition and adequate rest for best results.\"\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "intents_data = {\n",
        "            'pushups_beginner': [\n",
        "                'how to do push ups for beginners', 'pushup tutorial beginner', 'start doing pushups',\n",
        "                'pushup form beginner', 'learn pushups basics', 'pushup technique new', 'beginner pushup guide'\n",
        "            ],\n",
        "            'pushups_progression': [\n",
        "                'pushup progression', 'advance pushups', 'harder pushups', 'pushup variations',\n",
        "                'improve pushups', 'pushup next level', 'pushup difficulty increase'\n",
        "            ],\n",
        "            'pushups_mistakes': [\n",
        "                'pushup mistakes', 'wrong pushup form', 'pushup errors', 'bad pushup technique',\n",
        "                'pushup form check', 'common pushup problems', 'pushup corrections'\n",
        "            ],\n",
        "            'pullups_beginner': [\n",
        "                'pullup for beginners', 'how to start pullups', 'pullup tutorial beginner', 'learn pullups',\n",
        "                'pullup basics', 'first pullup', 'pullup assistance beginner'\n",
        "            ],\n",
        "            'pullups_assistance': [\n",
        "                'assisted pullups', 'pullup bands', 'pullup machine', 'negative pullups',\n",
        "                'pullup help', 'pullup support', 'easier pullups'\n",
        "            ],\n",
        "            'pullups_grip': [\n",
        "                'pullup grip', 'pullup hand position', 'wide grip pullups', 'chin up vs pullup',\n",
        "                'pullup grip width', 'pullup grip types', 'pullup hand placement'\n",
        "            ],\n",
        "            'hammer_curl_form': [\n",
        "                'hammer curl form', 'hammer curl technique', 'how to hammer curl', 'hammer curl beginner',\n",
        "                'hammer curl proper form', 'hammer curl tutorial', 'hammer curl basics'\n",
        "            ],\n",
        "            'hammer_curl_weight': [\n",
        "                'hammer curl weight', 'hammer curl dumbbell size', 'hammer curl weight selection',\n",
        "                'how heavy hammer curl', 'hammer curl starting weight', 'hammer curl weight beginner'\n",
        "            ],\n",
        "            'bench_press_beginner': [\n",
        "                'bench press beginner', 'how to bench press', 'bench press tutorial', 'bench press form',\n",
        "                'bench press technique', 'bench press basics', 'learn bench press'\n",
        "            ],\n",
        "            'bench_press_safety': [\n",
        "                'bench press safety', 'bench press spotter', 'bench press accidents', 'safe bench press',\n",
        "                'bench press precautions', 'bench press injury prevention', 'bench press risks'\n",
        "            ],\n",
        "            'bench_press_grip': [\n",
        "                'bench press grip', 'bench press hand position', 'bench press grip width',\n",
        "                'bench press bar grip', 'bench press hand placement', 'bench press grip technique'\n",
        "            ],\n",
        "            'squat_beginner': [\n",
        "                'squat for beginners', 'how to squat', 'squat tutorial', 'squat form beginner',\n",
        "                'basic squat technique', 'learn squats', 'squat basics'\n",
        "            ],\n",
        "            'squat_depth': [\n",
        "                'squat depth', 'how low squat', 'squat range motion', 'deep squats',\n",
        "                'squat bottom position', 'squat depth proper', 'full squat'\n",
        "            ],\n",
        "            'squat_knee_issues': [\n",
        "                'squat knee pain', 'squat knee problems', 'squats hurt knees', 'knee safe squats',\n",
        "                'squat knee injury', 'squat knee protection', 'squats bad knees'\n",
        "            ],\n",
        "            'workout_frequency': [\n",
        "                'how often workout', 'workout frequency', 'training frequency', 'workout schedule',\n",
        "                'how many times week workout', 'workout routine frequency', 'training schedule'\n",
        "            ],\n",
        "            'rest_recovery': [\n",
        "                'rest between workouts', 'recovery time', 'muscle recovery', 'rest days',\n",
        "                'workout recovery', 'how long rest', 'recovery period'\n",
        "            ],\n",
        "            'sets_reps': [\n",
        "                'how many sets reps', 'sets and reps', 'rep ranges', 'set rep scheme',\n",
        "                'how many reps', 'rep count', 'set count'\n",
        "            ],\n",
        "            'warm_up': [\n",
        "                'warm up exercises', 'pre workout warmup', 'how to warm up', 'warmup routine',\n",
        "                'warm up before workout', 'workout preparation', 'exercise warmup'\n",
        "            ],\n",
        "            'motivation': [\n",
        "                'workout motivation', 'fitness motivation', 'stay motivated', 'exercise motivation',\n",
        "                'motivation to workout', 'fitness inspiration', 'workout encouragement'\n",
        "            ],\n",
        "            'general_advice': [\n",
        "                'fitness advice', 'workout tips', 'exercise advice', 'fitness tips',\n",
        "                'general fitness', 'workout guidance', 'exercise help'\n",
        "            ]\n",
        "        }\n",
        "# Update the response dictionary\n",
        "response.update({\n",
        "    # Push-ups\n",
        "    'pushups_daily': \"Daily push-ups: It's okay to do push-ups daily if you're doing low-moderate volume. For high intensity, allow rest days. Listen to your body - if you feel sore or weak, take a day off.\",\n",
        "    'pushups_muscle_groups': \"Push-ups work: Chest (pectorals), shoulders (anterior deltoids), triceps, and core. Secondary muscles include serratus anterior and upper back for stabilization. It's a compound movement!\",\n",
        "    'pushups_hand_placement': \"Push-up hand positions: Standard (shoulder-width), wide grip (more chest), narrow/diamond (more triceps), staggered (uneven strength). Experiment to find what feels strongest for you.\",\n",
        "    'pushups_breathing': \"Push-up breathing: Inhale on the way down, exhale on the way up. Don't hold your breath! Proper breathing helps maintain core stability and provides oxygen to working muscles.\",\n",
        "    'pushups_plateau': \"Push-up plateau solutions: Increase reps per set, add more sets, try harder variations, add weight with a backpack, or incorporate tempo changes (slow negatives). Mix up your routine!\",\n",
        "\n",
        "    # Pull-ups\n",
        "    'pullups_progression': \"Pull-up progression: Dead hang → scapular pulls → negative pull-ups → assisted pull-ups → partial reps → full pull-ups → weighted pull-ups. Master each step before advancing.\",\n",
        "    'pullups_muscle_groups': \"Pull-ups target: Latissimus dorsi (main back muscle), rhomboids, middle traps, rear delts, biceps, and forearms. It's one of the best upper body compound exercises!\",\n",
        "    'pullups_frequency': \"Pull-up frequency: 2-3 times per week for beginners, allowing rest between sessions. Advanced users can train more frequently with varied grips and intensities.\",\n",
        "    'pullups_common_issues': \"Pull-up problems: Kipping (swinging), partial range of motion, gripping too tight, not engaging lats first. Focus on controlled movement, full range, and proper muscle activation.\",\n",
        "    'pullups_alternatives': \"Pull-up alternatives: Lat pulldowns, inverted rows, resistance band pull-aparts, or TRX rows. These help build the strength needed for eventual pull-ups.\",\n",
        "\n",
        "    # Hammer Curls\n",
        "    'hammer_curl_vs_bicep': \"Hammer curls vs bicep curls: Hammer curls target brachialis and brachioradialis more, giving arm thickness. Bicep curls focus on bicep peak. Include both for complete arm development.\",\n",
        "    'hammer_curl_tempo': \"Hammer curl tempo: 2 seconds up, 1 second squeeze, 3 seconds down. Controlled movement maximizes muscle tension and growth. Avoid bouncing or using momentum.\",\n",
        "    'hammer_curl_mistakes': \"Hammer curl errors: Swinging weights, moving elbows, partial range of motion, gripping too tight. Keep elbows fixed, full range, and maintain wrist alignment throughout.\",\n",
        "    'hammer_curl_variations': \"Hammer curl variations: Standing, seated, alternating arms, both arms together, cable hammer curls, or hammer curls with different grips. Vary to prevent plateaus.\",\n",
        "\n",
        "    # Bench Press\n",
        "    'bench_press_arch': \"Bench press arch: Slight natural arch is okay and safe. Keeps shoulders stable and reduces injury risk. Don't over-arch - your butt should stay on the bench. Focus on squeezing shoulder blades together.\",\n",
        "    'bench_press_breathing': \"Bench press breathing: Take deep breath at top, hold during descent and press, exhale at top or halfway up. This creates core stability and helps with heavier weights.\",\n",
        "    'bench_press_muscle_groups': \"Bench press works: Chest (pectorals), front deltoids, and triceps as primary movers. Secondary muscles include core, lats, and leg muscles for stability.\",\n",
        "    'bench_press_plateau': \"Bench press plateau: Vary rep ranges, try different grips, add pause reps, incorporate dumbbell variations, or focus on weak points. Sometimes deload and rebuild strength.\",\n",
        "    'bench_press_frequency': \"Bench press frequency: 2-3 times per week for most people. Allow 48-72 hours recovery between sessions. You can vary intensity - heavy, medium, light days.\",\n",
        "\n",
        "    # Squats\n",
        "    'squat_foot_position': \"Squat foot position: Shoulder-width apart, toes slightly pointed out (15-30°). Find your natural stance - everyone's hip anatomy is different. Your knees should track over your toes.\",\n",
        "    'squat_breathing': \"Squat breathing: Deep breath at top, hold during descent and ascent, exhale at top. This braces your core and provides stability for heavier weights.\",\n",
        "    'squat_muscle_groups': \"Squats work: Quadriceps, glutes, hamstrings, calves, and core. It's a full-body exercise that also engages upper back and shoulders for stability.\",\n",
        "    'squat_variations': \"Squat variations: Bodyweight, goblet squats, front squats, back squats, Bulgarian split squats, jump squats. Progress from bodyweight to weighted versions gradually.\",\n",
        "    'squat_common_mistakes': \"Squat mistakes: Knees caving in, forward lean, not going deep enough, weight on toes, looking up. Focus on knees out, chest up, weight on heels, neutral spine.\",\n",
        "    'squat_mobility': \"Squat mobility: Hip flexors, ankles, and thoracic spine affect squat depth. Stretch regularly, do mobility work, consider heel elevation if ankle mobility is limited.\",\n",
        "\n",
        "    # General Training\n",
        "    'progressive_overload': \"Progressive overload: Gradually increase weight, reps, or sets over time. This forces adaptation and growth. Track your workouts to ensure you're progressing. Small increases are better than big jumps.\",\n",
        "    'workout_structure': \"Workout structure: Warm-up → compound exercises → isolation exercises → cool-down. Start with big movements when you're fresh, finish with smaller accessory work.\",\n",
        "    'form_vs_weight': \"Form vs weight: Perfect form with lighter weight beats sloppy form with heavy weight. Master the movement first, then add weight. Your joints and muscles will thank you long-term.\",\n",
        "})\n",
        "\n",
        "# Update the intents_data dictionary\n",
        "intents_data.update({\n",
        "    # Push-ups\n",
        "    'pushups_daily': [\n",
        "        'daily pushups', 'pushups every day', 'pushup daily routine', 'daily pushup challenge',\n",
        "        'pushups everyday', 'can i do pushups daily', 'daily pushup workout', 'pushup daily training'\n",
        "    ],\n",
        "    'pushups_muscle_groups': [\n",
        "        'pushup muscles worked', 'what muscles do pushups work', 'pushup muscle groups',\n",
        "        'pushup muscle activation', 'muscles used in pushups', 'pushup muscle benefits',\n",
        "        'pushup muscle development', 'pushup muscle targeting'\n",
        "    ],\n",
        "    'pushups_hand_placement': [\n",
        "        'pushup hand position', 'pushup hand placement', 'pushup grip', 'pushup hand width',\n",
        "        'where to put hands pushup', 'pushup hand spacing', 'pushup hand alignment',\n",
        "        'pushup hand variations', 'pushup grip width'\n",
        "    ],\n",
        "    'pushups_breathing': [\n",
        "        'pushup breathing', 'how to breathe doing pushups', 'pushup breathing technique',\n",
        "        'breathing during pushups', 'pushup breath control', 'pushup breathing pattern',\n",
        "        'proper breathing pushups', 'pushup respiratory technique'\n",
        "    ],\n",
        "    'pushups_plateau': [\n",
        "        'pushup plateau', 'stuck at pushups', 'cant improve pushups', 'pushup progress stuck',\n",
        "        'pushup plateau breakthrough', 'pushup stagnation', 'pushup improvement plateau',\n",
        "        'overcome pushup plateau', 'pushup progress stalled'\n",
        "    ],\n",
        "\n",
        "    # Pull-ups\n",
        "    'pullups_progression': [\n",
        "        'pullup progression', 'pullup advancement', 'pullup training progression', 'pullup improvement',\n",
        "        'pullup workout progression', 'get better at pullups', 'pullup skill development',\n",
        "        'pullup progression plan', 'pullup training program', 'pullup development stages'\n",
        "    ],\n",
        "    'pullups_muscle_groups': [\n",
        "        'pullup muscles worked', 'what muscles do pullups work', 'pullup muscle groups',\n",
        "        'pullup muscle activation', 'muscles used in pullups', 'pullup muscle benefits',\n",
        "        'pullup muscle development', 'pullup muscle targeting', 'pullup muscle engagement'\n",
        "    ],\n",
        "    'pullups_frequency': [\n",
        "        'pullup frequency', 'how often pullups', 'pullup training frequency', 'pullup schedule',\n",
        "        'pullup workout frequency', 'pullup training schedule', 'how many times pullups',\n",
        "        'pullup routine frequency', 'pullup training days'\n",
        "    ],\n",
        "    'pullups_common_issues': [\n",
        "        'pullup problems', 'pullup issues', 'pullup difficulties', 'pullup challenges',\n",
        "        'pullup common mistakes', 'pullup form problems', 'pullup technique issues',\n",
        "        'pullup execution problems', 'pullup performance issues'\n",
        "    ],\n",
        "    'pullups_alternatives': [\n",
        "        'pullup alternatives', 'pullup substitutes', 'exercises instead of pullups',\n",
        "        'pullup replacement exercises', 'pullup alternative movements', 'pullup substitutions',\n",
        "        'exercises like pullups', 'pullup equivalent exercises'\n",
        "    ],\n",
        "\n",
        "    # Hammer Curls\n",
        "    'hammer_curl_vs_bicep': [\n",
        "        'hammer curl vs bicep curl', 'hammer curl vs regular curl', 'hammer curl difference',\n",
        "        'hammer curl vs traditional curl', 'hammer curl comparison', 'hammer curl benefits vs bicep curl',\n",
        "        'hammer curl vs standard curl', 'hammer curl vs normal curl'\n",
        "    ],\n",
        "    'hammer_curl_tempo': [\n",
        "        'hammer curl tempo', 'hammer curl speed', 'hammer curl timing', 'hammer curl pace',\n",
        "        'hammer curl rhythm', 'hammer curl cadence', 'hammer curl rep speed', 'hammer curl control'\n",
        "    ],\n",
        "    'hammer_curl_mistakes': [\n",
        "        'hammer curl mistakes', 'hammer curl errors', 'hammer curl form problems',\n",
        "        'hammer curl technique issues', 'hammer curl common mistakes', 'hammer curl wrong form',\n",
        "        'hammer curl execution errors', 'hammer curl performance mistakes'\n",
        "    ],\n",
        "    'hammer_curl_variations': [\n",
        "        'hammer curl variations', 'hammer curl types', 'hammer curl alternatives',\n",
        "        'different hammer curls', 'hammer curl exercise variations', 'hammer curl modifications',\n",
        "        'hammer curl workout variations', 'hammer curl movement variations'\n",
        "    ],\n",
        "\n",
        "    # Bench Press\n",
        "    'bench_press_arch': [\n",
        "        'bench press arch', 'bench press back arch', 'bench press spine position',\n",
        "        'bench press body position', 'bench press setup', 'bench press posture',\n",
        "        'bench press back position', 'bench press arch technique'\n",
        "    ],\n",
        "    'bench_press_breathing': [\n",
        "        'bench press breathing', 'how to breathe bench press', 'bench press breathing technique',\n",
        "        'breathing during bench press', 'bench press breath control', 'bench press breathing pattern',\n",
        "        'proper breathing bench press', 'bench press respiratory technique'\n",
        "    ],\n",
        "    'bench_press_muscle_groups': [\n",
        "        'bench press muscles worked', 'what muscles does bench press work', 'bench press muscle groups',\n",
        "        'bench press muscle activation', 'muscles used in bench press', 'bench press muscle benefits',\n",
        "        'bench press muscle development', 'bench press muscle targeting'\n",
        "    ],\n",
        "    'bench_press_plateau': [\n",
        "        'bench press plateau', 'stuck at bench press', 'cant improve bench press', 'bench press progress stuck',\n",
        "        'bench press plateau breakthrough', 'bench press stagnation', 'bench press improvement plateau',\n",
        "        'overcome bench press plateau', 'bench press progress stalled'\n",
        "    ],\n",
        "    'bench_press_frequency': [\n",
        "        'bench press frequency', 'how often bench press', 'bench press training frequency',\n",
        "        'bench press schedule', 'bench press workout frequency', 'bench press training schedule',\n",
        "        'how many times bench press', 'bench press routine frequency'\n",
        "    ],\n",
        "\n",
        "    # Squats\n",
        "    'squat_foot_position': [\n",
        "        'squat foot position', 'squat stance', 'squat foot placement', 'squat foot width',\n",
        "        'where to put feet squat', 'squat foot spacing', 'squat foot alignment',\n",
        "        'squat stance width', 'squat foot angle'\n",
        "    ],\n",
        "    'squat_breathing': [\n",
        "        'squat breathing', 'how to breathe squatting', 'squat breathing technique',\n",
        "        'breathing during squats', 'squat breath control', 'squat breathing pattern',\n",
        "        'proper breathing squats', 'squat respiratory technique'\n",
        "    ],\n",
        "    'squat_muscle_groups': [\n",
        "        'squat muscles worked', 'what muscles do squats work', 'squat muscle groups',\n",
        "        'squat muscle activation', 'muscles used in squats', 'squat muscle benefits',\n",
        "        'squat muscle development', 'squat muscle targeting'\n",
        "    ],\n",
        "    'squat_variations': [\n",
        "        'squat variations', 'squat types', 'different squats', 'squat alternatives',\n",
        "        'squat exercise variations', 'squat modifications', 'squat workout variations',\n",
        "        'squat movement variations', 'squat training variations'\n",
        "    ],\n",
        "    'squat_common_mistakes': [\n",
        "        'squat mistakes', 'squat errors', 'squat form problems', 'squat technique issues',\n",
        "        'squat common mistakes', 'squat wrong form', 'squat execution errors',\n",
        "        'squat performance mistakes', 'squat form issues'\n",
        "    ],\n",
        "    'squat_mobility': [\n",
        "        'squat mobility', 'squat flexibility', 'squat mobility exercises', 'squat mobility training',\n",
        "        'improve squat mobility', 'squat mobility work', 'squat flexibility training',\n",
        "        'squat mobility drills', 'squat range of motion'\n",
        "    ],\n",
        "\n",
        "    # General Training\n",
        "    'progressive_overload': [\n",
        "        'progressive overload', 'workout progression', 'training progression', 'exercise progression',\n",
        "        'progressive training', 'workout advancement', 'training advancement',\n",
        "        'progressive overload principle', 'workout progress', 'training progress'\n",
        "    ],\n",
        "    'workout_structure': [\n",
        "        'workout structure', 'workout organization', 'workout order', 'exercise order',\n",
        "        'workout planning', 'training structure', 'workout routine structure',\n",
        "        'workout layout', 'exercise sequence', 'workout arrangement'\n",
        "    ],\n",
        "    'form_vs_weight': [\n",
        "        'form vs weight', 'form over weight', 'proper form', 'exercise form',\n",
        "        'technique vs weight', 'form importance', 'weight vs form', 'good form',\n",
        "        'exercise technique', 'proper technique', 'form first'\n",
        "    ]\n",
        "})"
      ],
      "metadata": {
        "id": "aRCyy7to8sVD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNdwTjcr64Nz",
        "outputId": "ca0f8c45-c07a-4de0-f0fd-07445a828c81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LSTM model...\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 100ms/step - accuracy: 0.0080 - loss: 3.8716 - val_accuracy: 0.0260 - val_loss: 3.8684\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.0216 - loss: 3.8660 - val_accuracy: 0.0260 - val_loss: 3.8650\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0201 - loss: 3.8655 - val_accuracy: 0.0260 - val_loss: 3.8617\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0733 - loss: 3.8586 - val_accuracy: 0.0390 - val_loss: 3.8569\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0456 - loss: 3.8555 - val_accuracy: 0.0519 - val_loss: 3.8503\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0378 - loss: 3.8462 - val_accuracy: 0.0649 - val_loss: 3.8400\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0676 - loss: 3.8300 - val_accuracy: 0.0649 - val_loss: 3.8237\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0544 - loss: 3.8159 - val_accuracy: 0.0519 - val_loss: 3.7944\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0700 - loss: 3.7757 - val_accuracy: 0.0390 - val_loss: 3.7612\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0538 - loss: 3.7402 - val_accuracy: 0.1169 - val_loss: 3.7184\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1080 - loss: 3.6877 - val_accuracy: 0.0779 - val_loss: 3.5858\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1072 - loss: 3.5360 - val_accuracy: 0.1169 - val_loss: 3.4097\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1363 - loss: 3.4290 - val_accuracy: 0.1429 - val_loss: 3.2172\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1416 - loss: 3.2447 - val_accuracy: 0.2078 - val_loss: 3.0623\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1353 - loss: 3.1222 - val_accuracy: 0.2078 - val_loss: 2.9067\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1661 - loss: 2.9154 - val_accuracy: 0.2987 - val_loss: 2.6611\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2624 - loss: 2.6528 - val_accuracy: 0.3896 - val_loss: 2.5276\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2849 - loss: 2.5618 - val_accuracy: 0.3636 - val_loss: 2.3328\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3340 - loss: 2.4177 - val_accuracy: 0.5195 - val_loss: 2.1635\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3933 - loss: 2.1939 - val_accuracy: 0.4805 - val_loss: 2.0596\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4734 - loss: 2.0168 - val_accuracy: 0.5065 - val_loss: 1.9513\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4633 - loss: 1.9540 - val_accuracy: 0.6494 - val_loss: 1.8352\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4382 - loss: 1.8539 - val_accuracy: 0.5844 - val_loss: 1.7915\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4664 - loss: 1.7824 - val_accuracy: 0.6883 - val_loss: 1.6722\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5835 - loss: 1.5795 - val_accuracy: 0.6753 - val_loss: 1.5869\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5748 - loss: 1.5501 - val_accuracy: 0.7013 - val_loss: 1.5160\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5879 - loss: 1.4951 - val_accuracy: 0.7143 - val_loss: 1.4618\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6527 - loss: 1.3739 - val_accuracy: 0.7273 - val_loss: 1.3903\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7006 - loss: 1.3386 - val_accuracy: 0.7273 - val_loss: 1.3373\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7175 - loss: 1.1761 - val_accuracy: 0.7143 - val_loss: 1.3418\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7442 - loss: 1.1901 - val_accuracy: 0.7662 - val_loss: 1.2422\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7560 - loss: 1.1278 - val_accuracy: 0.7403 - val_loss: 1.1963\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7617 - loss: 1.0756 - val_accuracy: 0.7662 - val_loss: 1.1708\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7799 - loss: 1.0177 - val_accuracy: 0.7922 - val_loss: 1.1177\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7223 - loss: 1.0349 - val_accuracy: 0.7922 - val_loss: 1.0819\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7829 - loss: 0.9390 - val_accuracy: 0.8052 - val_loss: 1.0647\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7975 - loss: 0.9219 - val_accuracy: 0.7792 - val_loss: 1.0355\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8107 - loss: 0.8822 - val_accuracy: 0.7792 - val_loss: 1.0083\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8064 - loss: 0.8295 - val_accuracy: 0.8182 - val_loss: 1.0024\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8163 - loss: 0.7586 - val_accuracy: 0.8052 - val_loss: 0.9808\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8771 - loss: 0.7203 - val_accuracy: 0.7922 - val_loss: 0.9416\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8482 - loss: 0.7377 - val_accuracy: 0.8052 - val_loss: 0.9099\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8874 - loss: 0.6862 - val_accuracy: 0.8052 - val_loss: 0.9060\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8761 - loss: 0.6116 - val_accuracy: 0.8052 - val_loss: 0.8660\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8720 - loss: 0.6312 - val_accuracy: 0.8052 - val_loss: 0.8736\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9062 - loss: 0.5654 - val_accuracy: 0.7922 - val_loss: 0.8580\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9017 - loss: 0.5756 - val_accuracy: 0.7922 - val_loss: 0.8151\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8663 - loss: 0.6029 - val_accuracy: 0.7922 - val_loss: 0.8209\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9199 - loss: 0.5186 - val_accuracy: 0.8052 - val_loss: 0.8219\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8920 - loss: 0.5111 - val_accuracy: 0.8312 - val_loss: 0.8087\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9179 - loss: 0.4691 - val_accuracy: 0.8052 - val_loss: 0.7690\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8998 - loss: 0.4796 - val_accuracy: 0.7792 - val_loss: 0.8204\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9117 - loss: 0.4360 - val_accuracy: 0.7922 - val_loss: 0.7785\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9244 - loss: 0.4594 - val_accuracy: 0.7792 - val_loss: 0.8114\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9440 - loss: 0.4416 - val_accuracy: 0.8052 - val_loss: 0.7874\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9344 - loss: 0.4157 - val_accuracy: 0.8052 - val_loss: 0.7511\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9316 - loss: 0.4065 - val_accuracy: 0.8312 - val_loss: 0.7423\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9147 - loss: 0.4120 - val_accuracy: 0.8312 - val_loss: 0.7716\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9521 - loss: 0.3859 - val_accuracy: 0.8182 - val_loss: 0.7580\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9291 - loss: 0.3529 - val_accuracy: 0.8312 - val_loss: 0.7790\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9564 - loss: 0.3544 - val_accuracy: 0.7792 - val_loss: 0.7837\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9643 - loss: 0.3633 - val_accuracy: 0.7922 - val_loss: 0.7330\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9306 - loss: 0.3296 - val_accuracy: 0.8182 - val_loss: 0.7458\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9341 - loss: 0.3491 - val_accuracy: 0.8182 - val_loss: 0.7456\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9415 - loss: 0.3589 - val_accuracy: 0.8182 - val_loss: 0.7566\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9685 - loss: 0.3115 - val_accuracy: 0.8182 - val_loss: 0.7319\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9562 - loss: 0.3140 - val_accuracy: 0.8052 - val_loss: 0.7577\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9322 - loss: 0.3184 - val_accuracy: 0.8182 - val_loss: 0.7707\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9467 - loss: 0.2998 - val_accuracy: 0.8052 - val_loss: 0.7549\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9418 - loss: 0.2666 - val_accuracy: 0.8312 - val_loss: 0.7482\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9501 - loss: 0.2665 - val_accuracy: 0.8312 - val_loss: 0.7689\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9414 - loss: 0.2701 - val_accuracy: 0.8442 - val_loss: 0.7636\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9541 - loss: 0.2555 - val_accuracy: 0.8052 - val_loss: 0.7541\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9718 - loss: 0.1942 - val_accuracy: 0.8052 - val_loss: 0.7336\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9613 - loss: 0.2192 - val_accuracy: 0.8182 - val_loss: 0.7753\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9685 - loss: 0.2471 - val_accuracy: 0.7792 - val_loss: 0.7729\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9595 - loss: 0.2441 - val_accuracy: 0.8442 - val_loss: 0.7634\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9474 - loss: 0.2509 - val_accuracy: 0.8182 - val_loss: 0.7449\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9659 - loss: 0.2290 - val_accuracy: 0.8182 - val_loss: 0.7416\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9778 - loss: 0.1786 - val_accuracy: 0.8052 - val_loss: 0.7450\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9684 - loss: 0.1881 - val_accuracy: 0.7792 - val_loss: 0.8257\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9550 - loss: 0.2354 - val_accuracy: 0.8182 - val_loss: 0.7899\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9619 - loss: 0.1958 - val_accuracy: 0.8052 - val_loss: 0.7869\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9706 - loss: 0.2000 - val_accuracy: 0.8182 - val_loss: 0.8278\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9737 - loss: 0.1904 - val_accuracy: 0.8182 - val_loss: 0.7917\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9785 - loss: 0.2151 - val_accuracy: 0.8182 - val_loss: 0.8082\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9757 - loss: 0.1804 - val_accuracy: 0.8312 - val_loss: 0.7623\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9714 - loss: 0.1589 - val_accuracy: 0.8052 - val_loss: 0.7935\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9452 - loss: 0.1995 - val_accuracy: 0.7662 - val_loss: 0.8093\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9614 - loss: 0.1969 - val_accuracy: 0.7922 - val_loss: 0.7711\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9930 - loss: 0.1552 - val_accuracy: 0.7922 - val_loss: 0.8285\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9646 - loss: 0.1715 - val_accuracy: 0.7792 - val_loss: 0.8137\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9828 - loss: 0.1480 - val_accuracy: 0.7662 - val_loss: 0.8469\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9631 - loss: 0.1713 - val_accuracy: 0.8052 - val_loss: 0.8205\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9697 - loss: 0.1711 - val_accuracy: 0.8052 - val_loss: 0.8179\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9703 - loss: 0.1750 - val_accuracy: 0.8052 - val_loss: 0.7851\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9863 - loss: 0.1515 - val_accuracy: 0.7662 - val_loss: 0.8258\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9836 - loss: 0.1546 - val_accuracy: 0.8052 - val_loss: 0.7882\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9643 - loss: 0.1756 - val_accuracy: 0.7792 - val_loss: 0.8983\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9828 - loss: 0.1487 - val_accuracy: 0.8312 - val_loss: 0.7713\n",
            "\n",
            "=== LSTM Fitness Chatbot ===\n",
            "Type your fitness question. Type 'quit' to exit.\n",
            "\n",
            "You: push up\n",
            "Bot: Common push-up mistakes: Sagging hips, flaring elbows too wide, incomplete range of motion, holding breath. Keep core tight, elbows at 45°, chest touches ground, breathe throughout movement.\n",
            "[Intent: pushups_mistakes, Confidence: 0.597]\n",
            "\n",
            "You: how to do push ups\n",
            "Bot: For beginner push-ups: Start on your knees (modified push-up). Keep your body straight, hands shoulder-width apart. Lower chest to ground, push back up. Aim for 3 sets of 5-10 reps. Focus on form over quantity!\n",
            "[Intent: pushups_beginner, Confidence: 0.523]\n",
            "\n",
            "You: push up mistakes\n",
            "Bot: Common push-up mistakes: Sagging hips, flaring elbows too wide, incomplete range of motion, holding breath. Keep core tight, elbows at 45°, chest touches ground, breathe throughout movement.\n",
            "[Intent: pushups_mistakes, Confidence: 0.815]\n",
            "\n",
            "You: pull up\n",
            "Bot: Form vs weight: Perfect form with lighter weight beats sloppy form with heavy weight. Master the movement first, then add weight. Your joints and muscles will thank you long-term.\n",
            "[Intent: form_vs_weight, Confidence: 0.749]\n",
            "\n",
            "You: how to do pull up\n",
            "Bot: Form vs weight: Perfect form with lighter weight beats sloppy form with heavy weight. Master the movement first, then add weight. Your joints and muscles will thank you long-term.\n",
            "[Intent: form_vs_weight, Confidence: 0.749]\n",
            "\n",
            "You: quit\n",
            "Bot: Stay fit! 👋\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Download NLTK data if needed\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "\n",
        "\n",
        "# === Hyperparameters ===\n",
        "MAX_WORDS = 1000\n",
        "MAX_SEQ_LEN = 20\n",
        "EMBED_DIM = 50\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# === Preprocessing ===\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    words = text.split()\n",
        "    words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "texts = []\n",
        "labels = []\n",
        "intent_labels = list(intents_data.keys())\n",
        "\n",
        "for idx, (intent, examples) in enumerate(intents_data.items()):\n",
        "    for example in examples:\n",
        "        texts.append(preprocess_text(example))\n",
        "        labels.append(idx)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "X = pad_sequences(sequences, maxlen=MAX_SEQ_LEN)\n",
        "\n",
        "# One-hot encoding labels\n",
        "y = to_categorical(labels, num_classes=len(intent_labels))\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "# === Model with LSTM ===\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=MAX_WORDS, output_dim=EMBED_DIM, input_length=MAX_SEQ_LEN),\n",
        "    LSTM(64, return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(len(intent_labels), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(\"Training LSTM model...\")\n",
        "model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test, y_test))\n",
        "\n",
        "# === Prediction and Response ===\n",
        "def predict_intent(user_input, confidence_threshold=0.3):\n",
        "    processed = preprocess_text(user_input)\n",
        "    seq = tokenizer.texts_to_sequences([processed])\n",
        "    padded = pad_sequences(seq, maxlen=MAX_SEQ_LEN)\n",
        "    preds = model.predict(padded, verbose=0)\n",
        "    confidence = np.max(preds)\n",
        "    intent_idx = np.argmax(preds)\n",
        "    if confidence >= confidence_threshold:\n",
        "        return intent_labels[intent_idx], confidence\n",
        "    else:\n",
        "        return 'general_advice', confidence\n",
        "\n",
        "def get_response(user_input):\n",
        "    try:\n",
        "        intent, confidence = predict_intent(user_input)\n",
        "        return {\n",
        "            'response': response[intent],\n",
        "            'intent': intent,\n",
        "            'confidence': float(confidence)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            'response': response['general_advice'],\n",
        "            'intent': 'general_advice',\n",
        "            'confidence': 0.0,\n",
        "            'error': str(e)\n",
        "        }\n",
        "\n",
        "# === Chat Interface ===\n",
        "def main():\n",
        "    print(\"\\n=== LSTM Fitness Chatbot ===\")\n",
        "    print(\"Type your fitness question. Type 'quit' to exit.\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \").strip()\n",
        "        if user_input.lower() in ['quit', 'exit']:\n",
        "            print(\"Bot: Stay fit! 👋\")\n",
        "            break\n",
        "        result = get_response(user_input)\n",
        "        print(f\"Bot: {result['response']}\")\n",
        "        print(f\"[Intent: {result['intent']}, Confidence: {result['confidence']:.3f}]\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, SimpleRNN\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Download NLTK data if needed\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "\n",
        "\n",
        "# === Hyperparameters ===\n",
        "MAX_WORDS = 1000\n",
        "MAX_SEQ_LEN = 20\n",
        "EMBED_DIM = 50\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# === Preprocessing ===\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    words = text.split()\n",
        "    words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "texts = []\n",
        "labels = []\n",
        "intent_labels = list(intents_data.keys())\n",
        "\n",
        "for idx, (intent, examples) in enumerate(intents_data.items()):\n",
        "    for example in examples:\n",
        "        texts.append(preprocess_text(example))\n",
        "        labels.append(idx)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "X = pad_sequences(sequences, maxlen=MAX_SEQ_LEN)\n",
        "\n",
        "# One-hot encoding labels\n",
        "y = to_categorical(labels, num_classes=len(intent_labels))\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "# === Model with LSTM ===\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=MAX_WORDS, output_dim=EMBED_DIM, input_length=MAX_SEQ_LEN),\n",
        "    SimpleRNN(64, return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(len(intent_labels), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(\"Training LSTM model...\")\n",
        "model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test, y_test))\n",
        "\n",
        "# === Prediction and Response ===\n",
        "def predict_intent(user_input, confidence_threshold=0.3):\n",
        "    processed = preprocess_text(user_input)\n",
        "    seq = tokenizer.texts_to_sequences([processed])\n",
        "    padded = pad_sequences(seq, maxlen=MAX_SEQ_LEN)\n",
        "    preds = model.predict(padded, verbose=0)\n",
        "    confidence = np.max(preds)\n",
        "    intent_idx = np.argmax(preds)\n",
        "    if confidence >= confidence_threshold:\n",
        "        return intent_labels[intent_idx], confidence\n",
        "    else:\n",
        "        return 'general_advice', confidence\n",
        "\n",
        "def get_response(user_input):\n",
        "    try:\n",
        "        intent, confidence = predict_intent(user_input)\n",
        "        return {\n",
        "            'response': response[intent],\n",
        "            'intent': intent,\n",
        "            'confidence': float(confidence)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            'response': response['general_advice'],\n",
        "            'intent': 'general_advice',\n",
        "            'confidence': 0.0,\n",
        "            'error': str(e)\n",
        "        }\n",
        "\n",
        "# === Chat Interface ===\n",
        "def main():\n",
        "    print(\"\\n=== LSTM Fitness Chatbot ===\")\n",
        "    print(\"Type your fitness question. Type 'quit' to exit.\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \").strip()\n",
        "        if user_input.lower() in ['quit', 'exit']:\n",
        "            print(\"Bot: Stay fit! 👋\")\n",
        "            break\n",
        "        result = get_response(user_input)\n",
        "        print(f\"Bot: {result['response']}\")\n",
        "        print(f\"[Intent: {result['intent']}, Confidence: {result['confidence']:.3f}]\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kas1WliG-cva",
        "outputId": "f7376523-e3b6-4238-cb67-96e537c6554e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LSTM model...\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.0114 - loss: 3.8840 - val_accuracy: 0.0519 - val_loss: 3.8673\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0290 - loss: 3.8692 - val_accuracy: 0.0130 - val_loss: 3.8612\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0763 - loss: 3.8377 - val_accuracy: 0.0649 - val_loss: 3.8509\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0873 - loss: 3.8314 - val_accuracy: 0.0649 - val_loss: 3.8362\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0738 - loss: 3.8149 - val_accuracy: 0.0779 - val_loss: 3.8182\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1203 - loss: 3.7711 - val_accuracy: 0.0909 - val_loss: 3.7930\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0899 - loss: 3.7503 - val_accuracy: 0.0649 - val_loss: 3.7549\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1530 - loss: 3.6911 - val_accuracy: 0.1039 - val_loss: 3.7024\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1755 - loss: 3.6141 - val_accuracy: 0.1169 - val_loss: 3.6341\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1690 - loss: 3.5559 - val_accuracy: 0.1039 - val_loss: 3.5562\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1460 - loss: 3.4876 - val_accuracy: 0.1429 - val_loss: 3.4587\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1522 - loss: 3.3110 - val_accuracy: 0.1688 - val_loss: 3.3485\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1920 - loss: 3.2799 - val_accuracy: 0.2078 - val_loss: 3.2320\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2395 - loss: 3.0970 - val_accuracy: 0.2208 - val_loss: 3.1031\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2580 - loss: 2.9160 - val_accuracy: 0.2727 - val_loss: 2.9828\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3338 - loss: 2.7573 - val_accuracy: 0.2857 - val_loss: 2.8303\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4097 - loss: 2.5690 - val_accuracy: 0.3247 - val_loss: 2.6903\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3829 - loss: 2.5039 - val_accuracy: 0.3377 - val_loss: 2.5908\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3974 - loss: 2.3026 - val_accuracy: 0.3636 - val_loss: 2.4768\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4311 - loss: 2.2159 - val_accuracy: 0.3377 - val_loss: 2.3845\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4543 - loss: 2.0211 - val_accuracy: 0.3766 - val_loss: 2.2762\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5664 - loss: 1.9891 - val_accuracy: 0.4156 - val_loss: 2.1914\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6016 - loss: 1.8355 - val_accuracy: 0.4026 - val_loss: 2.1337\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5356 - loss: 1.7042 - val_accuracy: 0.4156 - val_loss: 2.0495\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6192 - loss: 1.6103 - val_accuracy: 0.4805 - val_loss: 1.9725\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6412 - loss: 1.5374 - val_accuracy: 0.4935 - val_loss: 1.9051\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6908 - loss: 1.3762 - val_accuracy: 0.4805 - val_loss: 1.8645\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7191 - loss: 1.3473 - val_accuracy: 0.5195 - val_loss: 1.8293\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7029 - loss: 1.2913 - val_accuracy: 0.5584 - val_loss: 1.7785\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7242 - loss: 1.1907 - val_accuracy: 0.5455 - val_loss: 1.7371\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7229 - loss: 1.1612 - val_accuracy: 0.5195 - val_loss: 1.6918\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7312 - loss: 1.1364 - val_accuracy: 0.5714 - val_loss: 1.6661\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7852 - loss: 0.9890 - val_accuracy: 0.5714 - val_loss: 1.6505\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8158 - loss: 0.9046 - val_accuracy: 0.5714 - val_loss: 1.6138\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7982 - loss: 0.8742 - val_accuracy: 0.5844 - val_loss: 1.5829\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8150 - loss: 0.8136 - val_accuracy: 0.5195 - val_loss: 1.5865\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8175 - loss: 0.8710 - val_accuracy: 0.5584 - val_loss: 1.5356\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8351 - loss: 0.7766 - val_accuracy: 0.5714 - val_loss: 1.5162\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8286 - loss: 0.7943 - val_accuracy: 0.5974 - val_loss: 1.4929\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8492 - loss: 0.7127 - val_accuracy: 0.5974 - val_loss: 1.5027\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8272 - loss: 0.7034 - val_accuracy: 0.5584 - val_loss: 1.5032\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8969 - loss: 0.6534 - val_accuracy: 0.5974 - val_loss: 1.4784\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8219 - loss: 0.7333 - val_accuracy: 0.5974 - val_loss: 1.4464\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8860 - loss: 0.6076 - val_accuracy: 0.5714 - val_loss: 1.4397\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8949 - loss: 0.6042 - val_accuracy: 0.5844 - val_loss: 1.4354\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8875 - loss: 0.5656 - val_accuracy: 0.5844 - val_loss: 1.4268\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9174 - loss: 0.4923 - val_accuracy: 0.5974 - val_loss: 1.4024\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9254 - loss: 0.4912 - val_accuracy: 0.6104 - val_loss: 1.3828\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9034 - loss: 0.5062 - val_accuracy: 0.6104 - val_loss: 1.3872\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8944 - loss: 0.4981 - val_accuracy: 0.5844 - val_loss: 1.4094\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8806 - loss: 0.4851 - val_accuracy: 0.6104 - val_loss: 1.3712\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9124 - loss: 0.4484 - val_accuracy: 0.6364 - val_loss: 1.3678\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9008 - loss: 0.4703 - val_accuracy: 0.5974 - val_loss: 1.3890\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9207 - loss: 0.4187 - val_accuracy: 0.6104 - val_loss: 1.3533\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9309 - loss: 0.4121 - val_accuracy: 0.5974 - val_loss: 1.3996\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9491 - loss: 0.3193 - val_accuracy: 0.6234 - val_loss: 1.3924\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9208 - loss: 0.3695 - val_accuracy: 0.6104 - val_loss: 1.3860\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9601 - loss: 0.3159 - val_accuracy: 0.6104 - val_loss: 1.3812\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9495 - loss: 0.3318 - val_accuracy: 0.6104 - val_loss: 1.3897\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9578 - loss: 0.3101 - val_accuracy: 0.5974 - val_loss: 1.4070\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9444 - loss: 0.2983 - val_accuracy: 0.6234 - val_loss: 1.4033\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9401 - loss: 0.3102 - val_accuracy: 0.6364 - val_loss: 1.3671\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9450 - loss: 0.3098 - val_accuracy: 0.6364 - val_loss: 1.3610\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9588 - loss: 0.2622 - val_accuracy: 0.5974 - val_loss: 1.3769\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9527 - loss: 0.2754 - val_accuracy: 0.6104 - val_loss: 1.3605\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9423 - loss: 0.2878 - val_accuracy: 0.6494 - val_loss: 1.3550\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9717 - loss: 0.2246 - val_accuracy: 0.6753 - val_loss: 1.3686\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9416 - loss: 0.2951 - val_accuracy: 0.6753 - val_loss: 1.3564\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9722 - loss: 0.2306 - val_accuracy: 0.6364 - val_loss: 1.3597\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9811 - loss: 0.2318 - val_accuracy: 0.6623 - val_loss: 1.3510\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9791 - loss: 0.2233 - val_accuracy: 0.6623 - val_loss: 1.3899\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9683 - loss: 0.2055 - val_accuracy: 0.6234 - val_loss: 1.4123\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9696 - loss: 0.1917 - val_accuracy: 0.6623 - val_loss: 1.3834\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9645 - loss: 0.2190 - val_accuracy: 0.6234 - val_loss: 1.3830\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9752 - loss: 0.2120 - val_accuracy: 0.6494 - val_loss: 1.3788\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9590 - loss: 0.2019 - val_accuracy: 0.6623 - val_loss: 1.3735\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9794 - loss: 0.1808 - val_accuracy: 0.6234 - val_loss: 1.3784\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9778 - loss: 0.1799 - val_accuracy: 0.6234 - val_loss: 1.4040\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9718 - loss: 0.1793 - val_accuracy: 0.6234 - val_loss: 1.4024\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9723 - loss: 0.1904 - val_accuracy: 0.6364 - val_loss: 1.3754\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9761 - loss: 0.1415 - val_accuracy: 0.6494 - val_loss: 1.3780\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9892 - loss: 0.1376 - val_accuracy: 0.6494 - val_loss: 1.3468\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9734 - loss: 0.1504 - val_accuracy: 0.6494 - val_loss: 1.3628\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9767 - loss: 0.1505 - val_accuracy: 0.6494 - val_loss: 1.3818\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9703 - loss: 0.1625 - val_accuracy: 0.6623 - val_loss: 1.3889\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9854 - loss: 0.1288 - val_accuracy: 0.6364 - val_loss: 1.4306\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9642 - loss: 0.1723 - val_accuracy: 0.6494 - val_loss: 1.4322\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9694 - loss: 0.1508 - val_accuracy: 0.6494 - val_loss: 1.4315\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9778 - loss: 0.1517 - val_accuracy: 0.6494 - val_loss: 1.4387\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9856 - loss: 0.1378 - val_accuracy: 0.6364 - val_loss: 1.4220\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9744 - loss: 0.1626 - val_accuracy: 0.6623 - val_loss: 1.4113\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9714 - loss: 0.1286 - val_accuracy: 0.6753 - val_loss: 1.4009\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9738 - loss: 0.1326 - val_accuracy: 0.6623 - val_loss: 1.4093\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9930 - loss: 0.1161 - val_accuracy: 0.6494 - val_loss: 1.4036\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9772 - loss: 0.1409 - val_accuracy: 0.6883 - val_loss: 1.3775\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9854 - loss: 0.1223 - val_accuracy: 0.6753 - val_loss: 1.4114\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9781 - loss: 0.1216 - val_accuracy: 0.6623 - val_loss: 1.4154\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9844 - loss: 0.1138 - val_accuracy: 0.6234 - val_loss: 1.4615\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9981 - loss: 0.0951 - val_accuracy: 0.6623 - val_loss: 1.4362\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9928 - loss: 0.0898 - val_accuracy: 0.6883 - val_loss: 1.4177\n",
            "\n",
            "=== LSTM Fitness Chatbot ===\n",
            "Type your fitness question. Type 'quit' to exit.\n",
            "\n",
            "You: push up\n",
            "Bot: Form vs weight: Perfect form with lighter weight beats sloppy form with heavy weight. Master the movement first, then add weight. Your joints and muscles will thank you long-term.\n",
            "[Intent: form_vs_weight, Confidence: 0.361]\n",
            "\n",
            "You: quit\n",
            "Bot: Stay fit! 👋\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, SimpleRNN,GRU\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Download NLTK data if needed\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "\n",
        "\n",
        "# === Hyperparameters ===\n",
        "MAX_WORDS = 1000\n",
        "MAX_SEQ_LEN = 20\n",
        "EMBED_DIM = 50\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# === Preprocessing ===\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    words = text.split()\n",
        "    words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "texts = []\n",
        "labels = []\n",
        "intent_labels = list(intents_data.keys())\n",
        "\n",
        "for idx, (intent, examples) in enumerate(intents_data.items()):\n",
        "    for example in examples:\n",
        "        texts.append(preprocess_text(example))\n",
        "        labels.append(idx)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "X = pad_sequences(sequences, maxlen=MAX_SEQ_LEN)\n",
        "\n",
        "# One-hot encoding labels\n",
        "y = to_categorical(labels, num_classes=len(intent_labels))\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "# === Model with LSTM ===\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=MAX_WORDS, output_dim=EMBED_DIM, input_length=MAX_SEQ_LEN),\n",
        "    GRU(256, return_sequences=True),\n",
        "    Dropout(0.5),\n",
        "    GRU(256, return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(len(intent_labels), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(\"Training LSTM model...\")\n",
        "model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test, y_test))\n",
        "\n",
        "# === Prediction and Response ===\n",
        "def predict_intent(user_input, confidence_threshold=0.3):\n",
        "    processed = preprocess_text(user_input)\n",
        "    seq = tokenizer.texts_to_sequences([processed])\n",
        "    padded = pad_sequences(seq, maxlen=MAX_SEQ_LEN)\n",
        "    preds = model.predict(padded, verbose=0)\n",
        "    confidence = np.max(preds)\n",
        "    intent_idx = np.argmax(preds)\n",
        "    if confidence >= confidence_threshold:\n",
        "        return intent_labels[intent_idx], confidence\n",
        "    else:\n",
        "        return 'general_advice', confidence\n",
        "\n",
        "def get_response(user_input):\n",
        "    try:\n",
        "        intent, confidence = predict_intent(user_input)\n",
        "        return {\n",
        "            'response': response[intent],\n",
        "            'intent': intent,\n",
        "            'confidence': float(confidence)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            'response': response['general_advice'],\n",
        "            'intent': 'general_advice',\n",
        "            'confidence': 0.0,\n",
        "            'error': str(e)\n",
        "        }\n",
        "\n",
        "# === Chat Interface ===\n",
        "def main():\n",
        "    print(\"\\n=== LSTM Fitness Chatbot ===\")\n",
        "    print(\"Type your fitness question. Type 'quit' to exit.\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \").strip()\n",
        "        if user_input.lower() in ['quit', 'exit']:\n",
        "            print(\"Bot: Stay fit! 👋\")\n",
        "            break\n",
        "        result = get_response(user_input)\n",
        "        print(f\"Bot: {result['response']}\")\n",
        "        print(f\"[Intent: {result['intent']}, Confidence: {result['confidence']:.3f}]\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iozo8BhH-3jF",
        "outputId": "f8e2b25f-6700-4535-bf0e-daed271ad515"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training LSTM model...\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 194ms/step - accuracy: 0.0191 - loss: 3.8721 - val_accuracy: 0.0260 - val_loss: 3.8659\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.0251 - loss: 3.8675 - val_accuracy: 0.0260 - val_loss: 3.8599\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.0398 - loss: 3.8581 - val_accuracy: 0.0260 - val_loss: 3.8432\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 249ms/step - accuracy: 0.0156 - loss: 3.8319 - val_accuracy: 0.0909 - val_loss: 3.8013\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - accuracy: 0.0459 - loss: 3.7720 - val_accuracy: 0.0519 - val_loss: 3.7148\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - accuracy: 0.0568 - loss: 3.6710 - val_accuracy: 0.0909 - val_loss: 3.5080\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.0876 - loss: 3.4814 - val_accuracy: 0.1299 - val_loss: 3.2578\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.0880 - loss: 3.2214 - val_accuracy: 0.1688 - val_loss: 3.0146\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.1389 - loss: 2.9699 - val_accuracy: 0.2338 - val_loss: 2.7591\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 223ms/step - accuracy: 0.2155 - loss: 2.5905 - val_accuracy: 0.2468 - val_loss: 2.5154\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - accuracy: 0.2600 - loss: 2.4412 - val_accuracy: 0.2727 - val_loss: 2.3751\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.2923 - loss: 2.2592 - val_accuracy: 0.3506 - val_loss: 2.0957\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.3496 - loss: 1.9964 - val_accuracy: 0.4545 - val_loss: 1.9523\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.5525 - loss: 1.6732 - val_accuracy: 0.4675 - val_loss: 1.8199\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 0.5070 - loss: 1.4968 - val_accuracy: 0.4286 - val_loss: 1.7487\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.5961 - loss: 1.3804 - val_accuracy: 0.4935 - val_loss: 1.6265\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.6641 - loss: 1.1698 - val_accuracy: 0.5325 - val_loss: 1.5055\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - accuracy: 0.6725 - loss: 1.0678 - val_accuracy: 0.5714 - val_loss: 1.4577\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.7434 - loss: 0.9261 - val_accuracy: 0.5455 - val_loss: 1.4423\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.7994 - loss: 0.7346 - val_accuracy: 0.5714 - val_loss: 1.3131\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.8283 - loss: 0.7176 - val_accuracy: 0.6623 - val_loss: 1.2917\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.8377 - loss: 0.6340 - val_accuracy: 0.6623 - val_loss: 1.3075\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 0.8791 - loss: 0.5068 - val_accuracy: 0.6883 - val_loss: 1.2545\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.8958 - loss: 0.4722 - val_accuracy: 0.6753 - val_loss: 1.2339\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - accuracy: 0.8424 - loss: 0.4907 - val_accuracy: 0.6364 - val_loss: 1.1740\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.8833 - loss: 0.4309 - val_accuracy: 0.6753 - val_loss: 1.2202\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.9357 - loss: 0.3644 - val_accuracy: 0.7013 - val_loss: 1.1476\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.9230 - loss: 0.3513 - val_accuracy: 0.7143 - val_loss: 1.2506\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.9237 - loss: 0.3140 - val_accuracy: 0.6883 - val_loss: 1.0792\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 236ms/step - accuracy: 0.9463 - loss: 0.3023 - val_accuracy: 0.7013 - val_loss: 1.2218\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.9570 - loss: 0.2352 - val_accuracy: 0.7273 - val_loss: 1.0930\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.9335 - loss: 0.2504 - val_accuracy: 0.7273 - val_loss: 1.1835\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.9716 - loss: 0.1826 - val_accuracy: 0.7532 - val_loss: 1.1124\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.9809 - loss: 0.1725 - val_accuracy: 0.7403 - val_loss: 1.0520\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.9654 - loss: 0.1750 - val_accuracy: 0.7662 - val_loss: 1.1871\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.9827 - loss: 0.1453 - val_accuracy: 0.7403 - val_loss: 1.0995\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 271ms/step - accuracy: 0.9833 - loss: 0.1349 - val_accuracy: 0.7532 - val_loss: 1.0823\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 131ms/step - accuracy: 0.9828 - loss: 0.1350 - val_accuracy: 0.7532 - val_loss: 1.0889\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.9772 - loss: 0.1176 - val_accuracy: 0.7013 - val_loss: 1.1358\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9617 - loss: 0.1418 - val_accuracy: 0.7662 - val_loss: 1.0625\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.9960 - loss: 0.0951 - val_accuracy: 0.7532 - val_loss: 1.1279\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 283ms/step - accuracy: 0.9868 - loss: 0.0993 - val_accuracy: 0.7532 - val_loss: 1.1744\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 268ms/step - accuracy: 0.9900 - loss: 0.0967 - val_accuracy: 0.7662 - val_loss: 1.1315\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - accuracy: 0.9785 - loss: 0.1084 - val_accuracy: 0.7662 - val_loss: 1.1829\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - accuracy: 0.9784 - loss: 0.0919 - val_accuracy: 0.7662 - val_loss: 1.1865\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.9941 - loss: 0.0683 - val_accuracy: 0.7403 - val_loss: 1.2538\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 251ms/step - accuracy: 0.9799 - loss: 0.0816 - val_accuracy: 0.7532 - val_loss: 1.2696\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.9836 - loss: 0.0750 - val_accuracy: 0.7662 - val_loss: 1.2840\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.9612 - loss: 0.1061 - val_accuracy: 0.7662 - val_loss: 1.2608\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - accuracy: 0.9911 - loss: 0.0633 - val_accuracy: 0.7532 - val_loss: 1.1813\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 0.9936 - loss: 0.0661 - val_accuracy: 0.7662 - val_loss: 1.1476\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - accuracy: 0.9812 - loss: 0.0732 - val_accuracy: 0.7792 - val_loss: 1.1480\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - accuracy: 0.9942 - loss: 0.0558 - val_accuracy: 0.7662 - val_loss: 1.1461\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.9886 - loss: 0.0496 - val_accuracy: 0.7662 - val_loss: 1.1672\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 0.9960 - loss: 0.0540 - val_accuracy: 0.7532 - val_loss: 1.2059\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0414 - val_accuracy: 0.7532 - val_loss: 1.1593\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.9956 - loss: 0.0381 - val_accuracy: 0.7532 - val_loss: 1.2671\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.9883 - loss: 0.0460 - val_accuracy: 0.7792 - val_loss: 1.2570\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - accuracy: 0.9922 - loss: 0.0420 - val_accuracy: 0.7532 - val_loss: 1.1853\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - accuracy: 0.9979 - loss: 0.0384 - val_accuracy: 0.7662 - val_loss: 1.1951\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.9929 - loss: 0.0435 - val_accuracy: 0.7662 - val_loss: 1.2856\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.9949 - loss: 0.0384 - val_accuracy: 0.7532 - val_loss: 1.2618\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.9925 - loss: 0.0391 - val_accuracy: 0.7922 - val_loss: 1.1820\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 0.9939 - loss: 0.0375 - val_accuracy: 0.7532 - val_loss: 1.2323\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - accuracy: 0.9947 - loss: 0.0339 - val_accuracy: 0.7403 - val_loss: 1.2949\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0220 - val_accuracy: 0.7532 - val_loss: 1.2646\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.9957 - loss: 0.0316 - val_accuracy: 0.7662 - val_loss: 1.2502\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.9991 - loss: 0.0285 - val_accuracy: 0.7532 - val_loss: 1.3290\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.9879 - loss: 0.0358 - val_accuracy: 0.7532 - val_loss: 1.2698\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - accuracy: 0.9966 - loss: 0.0270 - val_accuracy: 0.7662 - val_loss: 1.2542\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 217ms/step - accuracy: 0.9956 - loss: 0.0389 - val_accuracy: 0.7792 - val_loss: 1.2889\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 0.9956 - loss: 0.0306 - val_accuracy: 0.7532 - val_loss: 1.2952\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 0.7922 - val_loss: 1.3135\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.9983 - loss: 0.0163 - val_accuracy: 0.7792 - val_loss: 1.3222\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.0218 - val_accuracy: 0.7792 - val_loss: 1.2778\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - accuracy: 0.9944 - loss: 0.0259 - val_accuracy: 0.7792 - val_loss: 1.2730\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - accuracy: 0.9914 - loss: 0.0339 - val_accuracy: 0.7792 - val_loss: 1.2954\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - accuracy: 0.9973 - loss: 0.0214 - val_accuracy: 0.7792 - val_loss: 1.3435\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.9987 - loss: 0.0219 - val_accuracy: 0.7792 - val_loss: 1.2952\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0164 - val_accuracy: 0.7792 - val_loss: 1.3225\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 0.7792 - val_loss: 1.3163\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0181 - val_accuracy: 0.7532 - val_loss: 1.2690\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9978 - loss: 0.0203 - val_accuracy: 0.7792 - val_loss: 1.3476\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.9956 - loss: 0.0307 - val_accuracy: 0.7922 - val_loss: 1.3470\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 189ms/step - accuracy: 0.9987 - loss: 0.0147 - val_accuracy: 0.7922 - val_loss: 1.3418\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.7922 - val_loss: 1.2956\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9898 - loss: 0.0215 - val_accuracy: 0.8052 - val_loss: 1.2650\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 0.9956 - loss: 0.0254 - val_accuracy: 0.7662 - val_loss: 1.3846\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.9991 - loss: 0.0197 - val_accuracy: 0.7922 - val_loss: 1.2983\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 0.9956 - loss: 0.0193 - val_accuracy: 0.7922 - val_loss: 1.2775\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.9870 - loss: 0.0299 - val_accuracy: 0.7922 - val_loss: 1.3514\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 185ms/step - accuracy: 0.9979 - loss: 0.0174 - val_accuracy: 0.7792 - val_loss: 1.3882\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.9991 - loss: 0.0159 - val_accuracy: 0.7792 - val_loss: 1.3891\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.9974 - loss: 0.0159 - val_accuracy: 0.8052 - val_loss: 1.3063\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - accuracy: 0.9979 - loss: 0.0171 - val_accuracy: 0.7792 - val_loss: 1.3926\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - accuracy: 0.9994 - loss: 0.0122 - val_accuracy: 0.7922 - val_loss: 1.3553\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 240ms/step - accuracy: 0.9991 - loss: 0.0161 - val_accuracy: 0.7922 - val_loss: 1.3630\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.9979 - loss: 0.0160 - val_accuracy: 0.7792 - val_loss: 1.4032\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 167ms/step - accuracy: 0.9967 - loss: 0.0112 - val_accuracy: 0.7792 - val_loss: 1.4075\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - accuracy: 0.9973 - loss: 0.0122 - val_accuracy: 0.7922 - val_loss: 1.4402\n",
            "\n",
            "=== LSTM Fitness Chatbot ===\n",
            "Type your fitness question. Type 'quit' to exit.\n",
            "\n",
            "You: push up\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f16517e5da0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot: Warm-up routine: 5-10 minutes light cardio, then dynamic stretches and movement prep. For upper body: arm circles, shoulder rolls. For lower body: leg swings, bodyweight squats. Prepare your body for work ahead!\n",
            "[Intent: warm_up, Confidence: 0.781]\n",
            "\n",
            "You: how to do poush ups\n",
            "Bot: For beginner push-ups: Start on your knees (modified push-up). Keep your body straight, hands shoulder-width apart. Lower chest to ground, push back up. Aim for 3 sets of 5-10 reps. Focus on form over quantity!\n",
            "[Intent: pushups_beginner, Confidence: 0.562]\n",
            "\n",
            "You: advanced push ups\n",
            "Bot: To progress push-ups: Master regular push-ups first (3x15). Then try: incline push-ups → regular → decline → diamond push-ups → one-arm push-ups. Increase reps gradually before moving to harder variations.\n",
            "[Intent: pushups_progression, Confidence: 0.978]\n",
            "\n",
            "You: hammer curl\n",
            "Bot: Hammer curl technique: Stand straight, dumbbells at sides with neutral grip (palms facing each other). Curl up keeping elbows stationary, squeeze at top, lower slowly. Don't swing or use momentum!\n",
            "[Intent: hammer_curl_form, Confidence: 0.998]\n",
            "\n",
            "You: how to do hammer curl\n",
            "Bot: Hammer curl technique: Stand straight, dumbbells at sides with neutral grip (palms facing each other). Curl up keeping elbows stationary, squeeze at top, lower slowly. Don't swing or use momentum!\n",
            "[Intent: hammer_curl_form, Confidence: 0.998]\n",
            "\n",
            "You: how to do squat\n",
            "Bot: Beginner squat: Stand with feet shoulder-width apart, toes slightly out. Keep chest up, core tight. Sit back like sitting in chair, knees track over toes. Go down until thighs parallel to floor, drive through heels to stand.\n",
            "[Intent: squat_beginner, Confidence: 0.993]\n",
            "\n",
            "You: advanced squat\n",
            "Bot: Squat variations: Bodyweight, goblet squats, front squats, back squats, Bulgarian split squats, jump squats. Progress from bodyweight to weighted versions gradually.\n",
            "[Intent: squat_variations, Confidence: 0.628]\n",
            "\n",
            "You: how to do pull ups\n",
            "Bot: For beginner push-ups: Start on your knees (modified push-up). Keep your body straight, hands shoulder-width apart. Lower chest to ground, push back up. Aim for 3 sets of 5-10 reps. Focus on form over quantity!\n",
            "[Intent: pushups_beginner, Confidence: 0.562]\n",
            "\n",
            "You: how to do bench press\n",
            "Bot: Beginner bench press: Lie flat, feet on floor, grip bar slightly wider than shoulders. Lower bar to chest with control, pause briefly, press up smoothly. Start with empty barbell (45 lbs) to learn form. Always use a spotter!\n",
            "[Intent: bench_press_beginner, Confidence: 0.998]\n",
            "\n",
            "You: quit\n",
            "Bot: Stay fit! 👋\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, tokenizer, filepath='fitness_lstm'):\n",
        "    \"\"\"Save the trained LSTM model and tokenizer\"\"\"\n",
        "    model.save(f\"{filepath}_model.h5\")\n",
        "    with open(f\"{filepath}_tokenizer.pkl\", 'wb') as f:\n",
        "        pickle.dump(tokenizer, f)\n",
        "    print(f\"Model and tokenizer saved to '{filepath}_model.h5' and '{filepath}_tokenizer.pkl'.\")\n",
        "\n",
        "def load_model_and_tokenizer(filepath='fitness_lstm'):\n",
        "    \"\"\"Load a trained LSTM model and tokenizer\"\"\"\n",
        "    from tensorflow.keras.models import load_model\n",
        "    model = load_model(f\"{filepath}_model.h5\")\n",
        "    with open(f\"{filepath}_tokenizer.pkl\", 'rb') as f:\n",
        "        tokenizer = pickle.load(f)\n",
        "    print(f\"Model and tokenizer loaded from '{filepath}_model.h5' and '{filepath}_tokenizer.pkl'.\")\n",
        "    return model, tokenizer\n"
      ],
      "metadata": {
        "id": "wV8nrK6-AnoY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model and tokenizer after training\n",
        "save_model(model, tokenizer, filepath='fitness_lstm')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd0A6djTAtcc",
        "outputId": "7f91f48e-8515-4a0a-826a-52945a5e659c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved to 'fitness_lstm_model.h5' and 'fitness_lstm_tokenizer.pkl'.\n"
          ]
        }
      ]
    }
  ]
}