Data Preprocessing
==================

Data preprocessing is a critical step in preparing raw video data for machine learning model training. This section details the comprehensive preprocessing pipeline used in I-Coach.

Overview
--------

The preprocessing pipeline transforms raw exercise videos into structured, normalized data suitable for machine learning algorithms. This involves video processing, pose estimation, feature extraction, and data cleaning.

Preprocessing Pipeline
----------------------

1. **Video Ingestion and Validation**
2. **Pose Estimation and Keypoint Extraction**
3. **Data Normalization and Standardization**
4. **Feature Engineering**
5. **Quality Filtering and Validation**
6. **Data Segmentation and Windowing**

Video Processing
----------------

Video Ingestion
~~~~~~~~~~~~~~~

**Format Standardization**

.. code-block:: python

   # Video format conversion
   SUPPORTED_FORMATS = ['.mp4', '.avi', '.mov', '.mkv']
   TARGET_FORMAT = '.mp4'
   TARGET_CODEC = 'h264'
   
   # Resolution standardization
   TARGET_RESOLUTION = (1920, 1080)
   MIN_RESOLUTION = (720, 480)

**Frame Rate Normalization**

- **Target FPS**: 30 frames per second
- **Interpolation**: Linear interpolation for upsampling
- **Decimation**: Frame dropping for downsampling
- **Temporal Consistency**: Maintaining smooth motion

Quality Assessment
~~~~~~~~~~~~~~~~~~

**Automated Quality Metrics**

.. code-block:: python

   def assess_video_quality(video_path):
       metrics = {
           'resolution': get_resolution(video_path),
           'brightness': calculate_brightness(video_path),
           'contrast': calculate_contrast(video_path),
           'sharpness': calculate_sharpness(video_path),
           'stability': assess_camera_shake(video_path)
       }
       return metrics

**Quality Thresholds**
- Minimum brightness: 30/255
- Minimum contrast ratio: 1.5
- Sharpness score: > 50 (Laplacian variance)
- Motion blur detection: SSIM-based assessment

Pose Estimation
---------------

MediaPipe Integration
~~~~~~~~~~~~~~~~~~~~~

**Holistic Pose Detection**

.. code-block:: python

   import mediapipe as mp
   
   mp_pose = mp.solutions.pose
   mp_holistic = mp.solutions.holistic
   
   def extract_pose_landmarks(video_path):
       with mp_holistic.Holistic(
           min_detection_confidence=0.5,
           min_tracking_confidence=0.5
       ) as holistic:
           # Process video frames
           landmarks_sequence = []
           for frame in video_frames:
               results = holistic.process(frame)
               landmarks_sequence.append(extract_keypoints(results))
       return landmarks_sequence

**Keypoint Extraction**
- **Body Landmarks**: 33 pose keypoints
- **Hand Landmarks**: 21 points per hand (42 total)
- **Face Landmarks**: 468 facial keypoints (optional)
- **Confidence Scores**: Visibility and presence confidence

Landmark Processing
~~~~~~~~~~~~~~~~~~~

**Coordinate Normalization**

.. code-block:: python

   def normalize_landmarks(landmarks, frame_width, frame_height):
       normalized = []
       for landmark in landmarks:
           # Normalize to [0, 1] range
           x_norm = landmark.x / frame_width
           y_norm = landmark.y / frame_height
           z_norm = landmark.z  # Already normalized
           
           # Apply person-centric normalization
           x_centered = x_norm - hip_center_x
           y_centered = y_norm - hip_center_y
           
           normalized.append([x_centered, y_centered, z_norm])
       return normalized

**Missing Data Handling**
- **Interpolation**: Linear interpolation for short gaps
- **Extrapolation**: Forward/backward fill for edge cases
- **Confidence Weighting**: Low-confidence points marked for review
- **Landmark Imputation**: ML-based prediction for missing keypoints

Feature Engineering
-------------------

Derived Features
~~~~~~~~~~~~~~~~

**Angular Features**

.. code-block:: python

   def calculate_joint_angles(landmarks):
       angles = {}
       
       # Elbow angle (shoulder-elbow-wrist)
       angles['elbow_left'] = calculate_angle(
           landmarks['shoulder_left'],
           landmarks['elbow_left'],
           landmarks['wrist_left']
       )
       
       # Knee angle (hip-knee-ankle)
       angles['knee_left'] = calculate_angle(
           landmarks['hip_left'],
           landmarks['knee_left'],
           landmarks['ankle_left']
       )
       
       return angles

**Velocity and Acceleration**

.. code-block:: python

   def calculate_motion_features(landmark_sequence):
       velocities = []
       accelerations = []
       
       for i in range(1, len(landmark_sequence)):
           # Calculate velocity (first derivative)
           velocity = (landmark_sequence[i] - landmark_sequence[i-1]) / dt
           velocities.append(velocity)
           
           # Calculate acceleration (second derivative)
           if i > 1:
               acceleration = (velocities[i-1] - velocities[i-2]) / dt
               accelerations.append(acceleration)
       
       return velocities, accelerations

**Geometric Features**
- **Body Proportions**: Limb length ratios
- **Symmetry Metrics**: Left-right body symmetry
- **Center of Mass**: Estimated body center movement
- **Bounding Box**: Body envelope dimensions

Temporal Features
~~~~~~~~~~~~~~~~~

**Movement Patterns**

.. code-block:: python

   def extract_temporal_features(sequence, window_size=30):
       features = []
       
       for i in range(len(sequence) - window_size + 1):
           window = sequence[i:i+window_size]
           
           window_features = {
               'mean_position': np.mean(window, axis=0),
               'std_position': np.std(window, axis=0),
               'range_motion': np.max(window, axis=0) - np.min(window, axis=0),
               'peak_velocity': np.max(np.abs(np.diff(window, axis=0))),
               'rhythm_score': calculate_rhythm_score(window)
           }
           
           features.append(window_features)
       
       return features

Data Normalization
------------------

Spatial Normalization
~~~~~~~~~~~~~~~~~~~~~~

**Person-Centric Scaling**

.. code-block:: python

   def person_centric_normalization(landmarks):
       # Use shoulder width as reference scale
       shoulder_width = calculate_distance(
           landmarks['shoulder_left'],
           landmarks['shoulder_right']
       )
       
       # Normalize all coordinates by shoulder width
       normalized_landmarks = landmarks / shoulder_width
       
       return normalized_landmarks

**Pose Alignment**
- **Hip Alignment**: Align hip axis as reference
- **Shoulder Leveling**: Correct for camera tilt
- **Height Normalization**: Scale by person height
- **Rotation Correction**: Front-facing pose alignment

Temporal Normalization
~~~~~~~~~~~~~~~~~~~~~~

**Sequence Length Standardization**

.. code-block:: python

   def normalize_sequence_length(sequence, target_length=90):
       current_length = len(sequence)
       
       if current_length < target_length:
           # Interpolate to extend sequence
           return interpolate_sequence(sequence, target_length)
       elif current_length > target_length:
           # Downsample to reduce sequence
           return downsample_sequence(sequence, target_length)
       else:
           return sequence

**Phase Alignment**
- **Rep Detection**: Identify exercise repetition boundaries
- **Phase Segmentation**: Concentric/eccentric phase detection
- **Time Warping**: Dynamic time warping for phase alignment
- **Rhythm Normalization**: Standardize exercise tempo

Data Segmentation
-----------------

Exercise Segmentation
~~~~~~~~~~~~~~~~~~~~~

**Repetition Detection**

.. code-block:: python

   def detect_repetitions(landmark_sequence):
       # Use primary joint movement for rep detection
       primary_joint_data = extract_primary_joint(landmark_sequence)
       
       # Apply peak detection algorithm
       peaks, valleys = find_peaks_and_valleys(primary_joint_data)
       
       # Segment into individual repetitions
       repetitions = []
       for i in range(len(peaks) - 1):
           rep_start = valleys[i]
           rep_end = valleys[i + 1]
           repetitions.append(landmark_sequence[rep_start:rep_end])
       
       return repetitions

**Phase Detection**
- **Concentric Phase**: Muscle shortening/lifting phase
- **Eccentric Phase**: Muscle lengthening/lowering phase
- **Isometric Holds**: Static position maintenance
- **Transition Points**: Phase boundary identification

Windowing Strategy
~~~~~~~~~~~~~~~~~~

**Sliding Windows**

.. code-block:: python

   def create_sliding_windows(sequence, window_size=30, overlap=15):
       windows = []
       step_size = window_size - overlap
       
       for i in range(0, len(sequence) - window_size + 1, step_size):
           window = sequence[i:i + window_size]
           windows.append(window)
       
       return windows

**Adaptive Windowing**
- **Movement-Based**: Windows based on movement phases
- **Quality-Based**: Variable size based on data quality
- **Context-Aware**: Exercise-specific window strategies
- **Overlap Strategy**: Optimal overlap for temporal continuity

Quality Control
---------------

Automated Validation
~~~~~~~~~~~~~~~~~~~~~

**Pose Quality Metrics**

.. code-block:: python

   def validate_pose_quality(landmarks):
       quality_checks = {
           'completeness': check_landmark_completeness(landmarks),
           'anatomical_plausibility': check_anatomical_constraints(landmarks),
           'temporal_consistency': check_temporal_smoothness(landmarks),
           'confidence_threshold': check_confidence_scores(landmarks)
       }
       
       overall_quality = calculate_composite_score(quality_checks)
       return overall_quality

**Filtering Criteria**
- **Confidence Threshold**: Minimum 70% landmark confidence
- **Completeness**: 95% of required landmarks present
- **Smoothness**: Maximum velocity/acceleration thresholds
- **Anatomical Validity**: Joint angle and distance constraints

Manual Review Process
~~~~~~~~~~~~~~~~~~~~~

**Flagged Data Review**
- **Low Confidence Samples**: Manual inspection required
- **Anomaly Detection**: Statistical outliers flagged
- **Edge Cases**: Unusual poses or movements
- **Quality Borderline**: Samples near threshold values

Output Data Structure
---------------------

Processed Data Format
~~~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   processed_sample = {
       'video_id': 'unique_identifier',
       'exercise_type': 'squat',
       'participant_id': 'anonymized_id',
       'landmarks': {
           'raw': raw_landmark_sequence,
           'normalized': normalized_landmarks,
           'features': engineered_features
       },
       'metadata': {
           'duration': 12.5,  # seconds
           'repetitions': 8,
           'quality_score': 0.92,
           'form_annotations': ['proper_depth', 'good_alignment']
       },
       'segments': {
           'repetitions': individual_rep_data,
           'phases': phase_segmented_data
       }
   }

Storage and Organization
~~~~~~~~~~~~~~~~~~~~~~~~

**File Structure**
- **Processed Videos**: H5 format for efficient access
- **Landmark Data**: NumPy arrays with metadata
- **Feature Matrices**: Structured feature vectors
- **Quality Reports**: JSON format validation results

Performance Optimization
------------------------

Processing Efficiency
~~~~~~~~~~~~~~~~~~~~~

**Batch Processing**

.. code-block:: python

   def batch_process_videos(video_list, batch_size=32):
       for i in range(0, len(video_list), batch_size):
           batch = video_list[i:i + batch_size]
           
           # Parallel processing using multiprocessing
           with Pool(processes=cpu_count()) as pool:
               results = pool.map(process_single_video, batch)
           
           # Save batch results
           save_batch_results(results, batch_index=i//batch_size)

**Memory Management**
- **Streaming Processing**: Process videos without full loading
- **Garbage Collection**: Explicit memory cleanup
- **Chunked Operations**: Process large videos in chunks
- **Efficient Data Types**: Use appropriate numeric precision

Preprocessing Validation
------------------------

Statistical Validation
~~~~~~~~~~~~~~~~~~~~~~

**Distribution Analysis**

.. code-block:: python

   def validate_preprocessing_quality():
       validation_metrics = {
           'landmark_distribution': analyze_landmark_distributions(),
           'feature_correlation': calculate_feature_correlations(),
           'temporal_consistency': measure_temporal_smoothness(),
           'normalization_effectiveness': validate_normalization()
       }
       
       return validation_metrics

**Quality Assurance**
- **Before/After Comparison**: Pre and post-processing analysis
- **Statistical Tests**: Distribution and consistency tests
- **Visual Inspection**: Sample visualization and review
- **Cross-Validation**: Processing consistency across batches
